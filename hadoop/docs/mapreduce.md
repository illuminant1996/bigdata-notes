# MAPREDUCE

 MapReduce是一种分布式的离线计算框架，是一种编程模型，用于大规模数据集的并行运算。将自己的程序运行在分布式系统上。概念是："Map(映射)"和"Reduce(归约)"。指定一个Map(映射)函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce(归约)函数，用来保证所有映射的键值对中的每一个共享相同的键组。
 
 [MapReduce运行模型](../pictures/mapreduce.jpg)<br>
 [MapReduce详细图解](../pictures/mapreduce1.jpg)<br>
 如图所示，MapReduce分为这几个阶段，下面分别进行讲解：<br>
 - input: 数据进入MapReduce的阶段，可以是HDFS或者本地的数据文件
 - split: MapReduce会对数据进行切片，默认一个分片是hdfs block块的大小，_**有多少个分片文件就会有多少个MapTask**_
 - mapping: 这个阶段把数据封装成了<K,V>形式，然后把数据放进内存环形缓冲区，这个缓冲区专门用来输出的，默认大小是100mb，并且在配置文件里为这个缓冲区设定了一个阀值，默认是0.80（这个大小和阀值都是可以在配置文件里进行配置的），同时map还会为输出操作启动一个守护线程，如果缓冲区的内存达到了阀值的80%时候，这个守护线程就会把内容写到磁盘上，这个过程叫spill，另外的20%内存可以继续写入要写进磁盘的数据，写入磁盘和写入内存操作是互不干扰的，如果缓存区被撑满了，那么map就会阻塞写入内存的操作，让写入磁盘操作完成后再继续执行写入内存操作。在写入磁盘的时候，还会进行排序操作。
 - shuffle: 写入磁盘的时候还会有一个partition分区操作，默认是对K进行hash取模，分区之后写入不同的文件当中，_**本阶段产生多少个文件就会有多少个ReduceTask**_
 - reduce: 拉取前面阶段产生在不同的DataNode节点上的数据文件，对相同的K进行merge操作，规约到一起计算出结果，保存到hdfs<br>
